## Papers on LLM Security / attacks
* [Visual Adversarial Examples Jailbreak Aligned Large Language Models](https://arxiv.org/pdf/2306.13213) 
* Many articles, blog posts and repos [here](https://github.com/corca-ai/awesome-llm-security?tab=readme-ov-file)

## Bug bounty, vulnerabilities on AI/LLM
* https://huntr.com/

## Open sources tools 

## Market solutions 

## Conferences
*

## Books
* https://nostarch.com/how-ai-works
* 
